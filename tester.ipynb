{
 "cells": [
  {
   "cell_type": "code",
   "id": "6518ebdd2c78de45",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-06T11:49:51.677108Z",
     "start_time": "2024-09-06T11:49:38.984438Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T11:49:51.689445Z",
     "start_time": "2024-09-06T11:49:51.679112Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define constants\n",
    "IMG_HEIGHT = 32\n",
    "IMG_WIDTH = 128\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "\n",
    "# Define paths\n",
    "data_dir = 'Datasets/IAM_Words'\n",
    "words_file = os.path.join(data_dir, 'words.txt')\n",
    "images_dir = os.path.join(data_dir, 'words')\n",
    "\n",
    "# Read and process words.txt\n",
    "def process_words_file(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            if not line.startswith('#'):\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) >= 9:\n",
    "                    image_id = parts[0]\n",
    "                    word = parts[-1]\n",
    "                    data.append((image_id, word))\n",
    "    return pd.DataFrame(data, columns=['image_id', 'word'])\n"
   ],
   "id": "4f71e3c713eef16",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T11:49:52.146415Z",
     "start_time": "2024-09-06T11:49:51.690773Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "df = process_words_file(words_file)\n",
    "\n",
    "# Split the data\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a dictionary mapping words to integer labels\n",
    "word_to_index = {word: idx for idx, word in enumerate(df['word'].unique())}\n",
    "num_classes = len(word_to_index)\n",
    "\n",
    "# Custom data generator\n",
    "class WordDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, dataframe, word_to_index, batch_size, img_size, images_dir, is_training=True):\n",
    "        self.dataframe = dataframe\n",
    "        self.word_to_index = word_to_index\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.images_dir = images_dir\n",
    "        self.is_training = is_training\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.dataframe) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # logger.info(f\"Fetching batch {idx+1}/{len(self)}\")\n",
    "        start_idx = idx * self.batch_size\n",
    "        end_idx = min((idx + 1) * self.batch_size, len(self.dataframe))\n",
    "        batch_df = self.dataframe.iloc[start_idx:end_idx]\n",
    "        \n",
    "        batch_x = []\n",
    "        batch_y = []\n",
    "        skipped_images = 0\n",
    "\n",
    "        for _, row in batch_df.iterrows():\n",
    "            img_path = os.path.join(self.images_dir, row['image_id'].split('-')[0], \n",
    "                                    '-'.join(row['image_id'].split('-')[:2]), \n",
    "                                    f\"{row['image_id']}.png\")\n",
    "            \n",
    "            try:\n",
    "                with Image.open(img_path) as img:\n",
    "                    img = img.convert('L')  # Convert to grayscale\n",
    "                    img = img.resize(self.img_size)\n",
    "                    img_array = np.array(img)\n",
    "                    img_array = img_array.reshape(self.img_size[0], self.img_size[1], 1)\n",
    "                    img_array = img_array / 255.0  # Normalize\n",
    "                    \n",
    "                batch_x.append(img_array)\n",
    "                label = np.zeros(len(self.word_to_index))\n",
    "                label[self.word_to_index[row['word']]] = 1\n",
    "                batch_y.append(label)\n",
    "            except (IOError, OSError, Image.UnidentifiedImageError):\n",
    "                logger.warning(f\"Error loading image: {img_path}\")\n",
    "                skipped_images += 1\n",
    "                continue  # Skip this image and continue with the next one\n",
    "\n",
    "        # logger.info(f\"Batch {idx+1}: Loaded {len(batch_x)} images, skipped {skipped_images}\")\n",
    "\n",
    "        if not batch_x:  # If all images in the batch were invalid\n",
    "            logger.warning(f\"All images in batch {idx+1} were invalid. Trying next batch.\")\n",
    "            return self.__getitem__((idx + 1) % len(self))  # Try the next batch\n",
    "\n",
    "        return np.array(batch_x), np.array(batch_y)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.is_training:\n",
    "            # logger.info(\"Shuffling training data for next epoch\")\n",
    "            self.dataframe = self.dataframe.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Create data generators\n",
    "train_generator = WordDataGenerator(train_df, word_to_index, BATCH_SIZE, (IMG_HEIGHT, IMG_WIDTH), images_dir)\n",
    "val_generator = WordDataGenerator(val_df, word_to_index, BATCH_SIZE, (IMG_HEIGHT, IMG_WIDTH), images_dir, is_training=False)\n",
    "\n",
    "# Define the model\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ],
   "id": "326caae56dd0d4e5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bulaya\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T12:52:21.581542Z",
     "start_time": "2024-09-06T11:49:52.147414Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate steps_per_epoch and validation_steps\n",
    "steps_per_epoch = len(train_generator)\n",
    "validation_steps = len(val_generator)\n",
    "\n",
    "\n",
    "print(f\"Training data size: {len(train_df)}\")\n",
    "print(f\"Validation data size: {len(val_df)}\")\n",
    "print(f\"Steps per epoch: {steps_per_epoch}\")\n",
    "print(f\"Validation steps: {validation_steps}\")\n",
    "\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=validation_steps\n",
    ")\n"
   ],
   "id": "acf0fec8f8132291",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: 92256\n",
      "Validation data size: 23064\n",
      "Steps per epoch: 2883\n",
      "Validation steps: 721\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bulaya\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1143/2883\u001B[0m \u001B[32m━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━\u001B[0m \u001B[1m5:19\u001B[0m 183ms/step - accuracy: 0.1018 - loss: 7.0082"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:Error loading image: Datasets/IAM_Words\\words\\a01\\a01-117\\a01-117-05-02.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m2883/2883\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 173ms/step - accuracy: 0.1628 - loss: 6.4286"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:Error loading image: Datasets/IAM_Words\\words\\r06\\r06-022\\r06-022-03-05.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m2883/2883\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m569s\u001B[0m 197ms/step - accuracy: 0.1628 - loss: 6.4283 - val_accuracy: 0.3276 - val_loss: 5.0796\n",
      "Epoch 2/20\n",
      "\u001B[1m2883/2883\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bulaya\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m2197/2883\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m1:28\u001B[0m 129ms/step - accuracy: 0.3436 - loss: 4.6142"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:Error loading image: Datasets/IAM_Words\\words\\a01\\a01-117\\a01-117-05-02.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m2883/2883\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 120ms/step - accuracy: 0.3473 - loss: 4.5834"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:Error loading image: Datasets/IAM_Words\\words\\r06\\r06-022\\r06-022-03-05.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m2883/2883\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m398s\u001B[0m 138ms/step - accuracy: 0.3474 - loss: 4.5833 - val_accuracy: 0.3848 - val_loss: 4.6361\n",
      "Epoch 4/20\n",
      "\u001B[1m2883/2883\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 5/20\n",
      "\u001B[1m 574/2883\u001B[0m \u001B[32m━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:02\u001B[0m 105ms/step - accuracy: 0.4024 - loss: 3.9366"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:Error loading image: Datasets/IAM_Words\\words\\a01\\a01-117\\a01-117-05-02.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m2882/2883\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 97ms/step - accuracy: 0.4081 - loss: 3.8879"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:Error loading image: Datasets/IAM_Words\\words\\r06\\r06-022\\r06-022-03-05.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m2883/2883\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m341s\u001B[0m 118ms/step - accuracy: 0.4081 - loss: 3.8878 - val_accuracy: 0.4248 - val_loss: 4.4459\n",
      "Epoch 6/20\n",
      "\u001B[1m2883/2883\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 7/20\n",
      "\u001B[1m1093/2883\u001B[0m \u001B[32m━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━\u001B[0m \u001B[1m4:40\u001B[0m 157ms/step - accuracy: 0.4417 - loss: 3.4231"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:Error loading image: Datasets/IAM_Words\\words\\a01\\a01-117\\a01-117-05-02.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m2882/2883\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 131ms/step - accuracy: 0.4461 - loss: 3.3833"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:Error loading image: Datasets/IAM_Words\\words\\r06\\r06-022\\r06-022-03-05.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m2883/2883\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m433s\u001B[0m 149ms/step - accuracy: 0.4461 - loss: 3.3833 - val_accuracy: 0.4447 - val_loss: 4.4960\n",
      "Epoch 8/20\n",
      "\u001B[1m2883/2883\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 9/20\n",
      "\u001B[1m1419/2883\u001B[0m \u001B[32m━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━\u001B[0m \u001B[1m2:34\u001B[0m 105ms/step - accuracy: 0.4764 - loss: 3.0016"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:Error loading image: Datasets/IAM_Words\\words\\a01\\a01-117\\a01-117-05-02.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m2883/2883\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 98ms/step - accuracy: 0.4785 - loss: 2.9876"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:Error loading image: Datasets/IAM_Words\\words\\r06\\r06-022\\r06-022-03-05.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m2883/2883\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m324s\u001B[0m 112ms/step - accuracy: 0.4785 - loss: 2.9876 - val_accuracy: 0.4614 - val_loss: 4.6600\n",
      "Epoch 10/20\n",
      "\u001B[1m2883/2883\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 11/20\n",
      "\u001B[1m1734/2883\u001B[0m \u001B[32m━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━\u001B[0m \u001B[1m1:49\u001B[0m 95ms/step - accuracy: 0.5026 - loss: 2.6743"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:Error loading image: Datasets/IAM_Words\\words\\a01\\a01-117\\a01-117-05-02.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m2883/2883\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 100ms/step - accuracy: 0.5024 - loss: 2.6744"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:Error loading image: Datasets/IAM_Words\\words\\r06\\r06-022\\r06-022-03-05.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m2883/2883\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m345s\u001B[0m 119ms/step - accuracy: 0.5024 - loss: 2.6744 - val_accuracy: 0.4703 - val_loss: 4.7765\n",
      "Epoch 12/20\n",
      "\u001B[1m2883/2883\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 13/20\n",
      "\u001B[1m 460/2883\u001B[0m \u001B[32m━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:30\u001B[0m 87ms/step - accuracy: 0.5366 - loss: 2.3867"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:Error loading image: Datasets/IAM_Words\\words\\a01\\a01-117\\a01-117-05-02.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m2882/2883\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 92ms/step - accuracy: 0.5286 - loss: 2.4043"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:Error loading image: Datasets/IAM_Words\\words\\r06\\r06-022\\r06-022-03-05.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m2883/2883\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m305s\u001B[0m 106ms/step - accuracy: 0.5286 - loss: 2.4043 - val_accuracy: 0.4763 - val_loss: 5.1051\n",
      "Epoch 14/20\n",
      "\u001B[1m2883/2883\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 15/20\n",
      "\u001B[1m2798/2883\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m8s\u001B[0m 100ms/step - accuracy: 0.5461 - loss: 2.1866"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:Error loading image: Datasets/IAM_Words\\words\\a01\\a01-117\\a01-117-05-02.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m2883/2883\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 100ms/step - accuracy: 0.5460 - loss: 2.1871"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:Error loading image: Datasets/IAM_Words\\words\\r06\\r06-022\\r06-022-03-05.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m2883/2883\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m338s\u001B[0m 117ms/step - accuracy: 0.5460 - loss: 2.1871 - val_accuracy: 0.4759 - val_loss: 5.2371\n",
      "Epoch 16/20\n",
      "\u001B[1m2883/2883\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 17/20\n",
      "\u001B[1m1812/2883\u001B[0m \u001B[32m━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━\u001B[0m \u001B[1m1:48\u001B[0m 101ms/step - accuracy: 0.5729 - loss: 1.9484"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:Error loading image: Datasets/IAM_Words\\words\\a01\\a01-117\\a01-117-05-02.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m2883/2883\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 101ms/step - accuracy: 0.5695 - loss: 1.9682"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:Error loading image: Datasets/IAM_Words\\words\\r06\\r06-022\\r06-022-03-05.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m2883/2883\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m344s\u001B[0m 119ms/step - accuracy: 0.5695 - loss: 1.9682 - val_accuracy: 0.4810 - val_loss: 5.3241\n",
      "Epoch 18/20\n",
      "\u001B[1m2883/2883\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 19/20\n",
      "\u001B[1m1212/2883\u001B[0m \u001B[32m━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━\u001B[0m \u001B[1m2:54\u001B[0m 104ms/step - accuracy: 0.6017 - loss: 1.7394"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:Error loading image: Datasets/IAM_Words\\words\\a01\\a01-117\\a01-117-05-02.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m2883/2883\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 105ms/step - accuracy: 0.5941 - loss: 1.7788"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:Error loading image: Datasets/IAM_Words\\words\\r06\\r06-022\\r06-022-03-05.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m2883/2883\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m352s\u001B[0m 122ms/step - accuracy: 0.5941 - loss: 1.7789 - val_accuracy: 0.4838 - val_loss: 5.5520\n",
      "Epoch 20/20\n",
      "\u001B[1m2883/2883\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T12:56:27.187577Z",
     "start_time": "2024-09-06T12:56:23.815818Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save the model\n",
    "model.save('word_classification_model.h5')\n",
    "model.save('word_classification_model.keras')\n",
    "\n",
    "# Convert to TensorFlow Lite format\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TensorFlow Lite model\n",
    "with open('word_classification_model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(\"Training completed and models saved.\")"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Bulaya\\AppData\\Local\\Temp\\tmpan3jxffc\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Bulaya\\AppData\\Local\\Temp\\tmpan3jxffc\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\Bulaya\\AppData\\Local\\Temp\\tmpan3jxffc'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 32, 128, 1), dtype=tf.float32, name='keras_tensor')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 13542), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  1933142224400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1933142223824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1933142224976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1933142226128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1933142225936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1933142224208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1933142226320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1933142226896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1933142224784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1933142227280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "Training completed and models saved.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9688923013b5797b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
