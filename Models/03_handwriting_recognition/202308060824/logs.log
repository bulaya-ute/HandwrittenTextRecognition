2023-08-06 09:19:52,133 - ImageReader - WARNING - Image Datasets\IAM_Words\words\r06\r06-022\r06-022-03-05.png could not be read, returning None.
2023-08-06 09:19:52,134 - DataProvider - WARNING - Data or annotation is None, marking for removal on epoch end.
2023-08-06 09:19:52,134 - DataProvider - WARNING - Data or annotation is None, skipping.
2023-08-06 09:22:49,457 - ImageReader - WARNING - Image Datasets\IAM_Words\words\a01\a01-117\a01-117-05-02.png could not be read, returning None.
2023-08-06 09:22:49,458 - DataProvider - WARNING - Data or annotation is None, marking for removal on epoch end.
2023-08-06 09:22:49,458 - DataProvider - WARNING - Data or annotation is None, skipping.
2023-08-06 09:26:17,315 - DataProvider - WARNING - Removing ['Datasets\\IAM_Words\\words\\r06\\r06-022\\r06-022-03-05.png', 'more'] from dataset.
2023-08-06 09:26:17,379 - DataProvider - WARNING - Removing ['Datasets\\IAM_Words\\words\\a01\\a01-117\\a01-117-05-02.png', 'Powell'] from dataset.
2023-08-06 09:30:54,037 - root - INFO - Epoch 0; loss: 12.639557838439941; CER: 0.8224144577980042; WER: 0.9123237729072571; val_loss: 11.242608070373535; val_CER: 0.6369568109512329; val_WER: 0.820858359336853
2023-08-06 10:18:00,847 - root - INFO - Epoch 1; loss: 9.199469566345215; CER: 0.5612796545028687; WER: 0.7726476788520813; val_loss: 8.020913124084473; val_CER: 0.5120694041252136; val_WER: 0.7751399278640747
2023-08-06 12:23:03,634 - root - INFO - Epoch 2; loss: 7.458261013031006; CER: 0.45053014159202576; WER: 0.7042323350906372; val_loss: 5.5633649826049805; val_CER: 0.3305065631866455; val_WER: 0.6150736212730408
2023-08-06 13:13:44,863 - root - INFO - Epoch 3; loss: 6.145909309387207; CER: 0.36825665831565857; WER: 0.6489839553833008; val_loss: 4.398470401763916; val_CER: 0.26371240615844727; val_WER: 0.5477918386459351
2023-08-06 14:03:07,586 - root - INFO - Epoch 4; loss: 5.260745048522949; CER: 0.3120422065258026; WER: 0.598435640335083; val_loss: 3.9523262977600098; val_CER: 0.2334834784269333; val_WER: 0.5055981874465942
2023-08-06 14:51:45,679 - root - INFO - Epoch 5; loss: 4.697215557098389; CER: 0.27716442942619324; WER: 0.5571260452270508; val_loss: 3.274226665496826; val_CER: 0.19696560502052307; val_WER: 0.4527265131473541
2023-08-06 15:45:08,335 - root - INFO - Epoch 6; loss: 4.3041205406188965; CER: 0.2549148499965668; WER: 0.5326122045516968; val_loss: 3.070067882537842; val_CER: 0.18613213300704956; val_WER: 0.4317851960659027
2023-08-06 16:36:46,566 - root - INFO - Epoch 7; loss: 4.033635139465332; CER: 0.23821419477462769; WER: 0.508374810218811; val_loss: 2.9202160835266113; val_CER: 0.17325282096862793; val_WER: 0.4177897572517395
2023-08-06 17:31:24,520 - root - INFO - Epoch 8; loss: 3.786389112472534; CER: 0.22402124106884003; WER: 0.4895631670951843; val_loss: 2.8239874839782715; val_CER: 0.17324863374233246; val_WER: 0.4098071753978729
2023-08-06 18:23:08,419 - root - INFO - Epoch 9; loss: 3.5575311183929443; CER: 0.2117815911769867; WER: 0.4721454381942749; val_loss: 2.434802532196045; val_CER: 0.14697693288326263; val_WER: 0.36564379930496216
2023-08-06 18:23:11,913 - tf2onnx.tfonnx - INFO - Using tensorflow=2.9.1, onnx=1.14.0, tf2onnx=1.14.0/8f8d49
2023-08-06 18:23:11,914 - tf2onnx.tfonnx - INFO - Using opset <onnx, 15>
2023-08-06 18:23:12,313 - tf2onnx.tf_utils - INFO - Computed 0 values for constant folding
2023-08-06 18:23:12,331 - tf2onnx.tf_utils - INFO - Computed 0 values for constant folding
2023-08-06 18:23:12,346 - tf2onnx.tf_utils - INFO - Computed 0 values for constant folding
2023-08-06 18:23:12,352 - tf2onnx.tf_utils - INFO - Computed 0 values for constant folding
2023-08-06 18:23:12,585 - tf2onnx.tf_utils - INFO - Computed 2 values for constant folding
2023-08-06 18:23:12,906 - tf2onnx.tfonnx - INFO - folding node using tf type=StridedSlice, name=model/bidirectional/forward_lstm/PartitionedCall/strided_slice
2023-08-06 18:23:12,906 - tf2onnx.tfonnx - INFO - folding node using tf type=StridedSlice, name=model/bidirectional/backward_lstm/PartitionedCall/strided_slice
2023-08-06 18:23:13,229 - tf2onnx.optimizer - INFO - Optimizing ONNX model
2023-08-06 18:23:14,921 - tf2onnx.optimizer - INFO - After optimization: BatchNormalization -18 (18->0), Cast -4 (11->7), Concat -4 (10->6), Const -129 (192->63), Expand -3 (4->1), Gather +2 (2->4), Identity -2 (2->0), Shape -1 (4->3), Slice -1 (5->4), Squeeze -3 (5->2), Transpose -81 (85->4), Unsqueeze -14 (17->3)
